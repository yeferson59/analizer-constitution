# Asistente Legal / Normativo (LangChain + LLMs)

Asistente inteligente para consultar leyes colombianas utilizando LangChain y m√∫ltiples proveedores de LLM.

## Caracter√≠sticas

- ü§ñ **Soporte Multi-Proveedor**: OpenAI, OpenRouter, Ollama, y Groq
- üìö **RAG (Retrieval Augmented Generation)**: B√∫squeda sem√°ntica en documentos legales
- üíæ **Vector Database**: Almacenamiento eficiente con FAISS/Chroma
- üîÑ **Gesti√≥n de Memoria**: Contexto conversacional con LangChain
- üéØ **Agentes ReAct**: Ejecuci√≥n inteligente de acciones
- üìù **Parsers Estructurados**: Respuestas en formato JSON validado
- üñ•Ô∏è **Interfaz Interactiva**: Widgets de Jupyter para demo

## Instalaci√≥n

### Requisitos Previos

- Python 3.13 o superior
- uv (recomendado) o pip

### Instalar Dependencias

Con uv:
```bash
uv sync
```

Con pip:
```bash
pip install -e .
```

## Configuraci√≥n

1. Copia el archivo de ejemplo de variables de entorno:
```bash
cp .env.example .env
```

2. Edita `.env` y configura las credenciales para el proveedor que desees usar:

### OpenAI
```env
LLM_PROVIDER=openai
OPENAI_API_KEY=tu_api_key_de_openai
OPENAI_MODEL=gpt-3.5-turbo
```

### OpenRouter
```env
LLM_PROVIDER=openrouter
OPENROUTER_API_KEY=tu_api_key_de_openrouter
OPENROUTER_MODEL=google/gemini-2.0-flash-exp:free
```

### Ollama (Local)
```env
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2
```

### Groq
```env
LLM_PROVIDER=groq
GROQ_API_KEY=tu_api_key_de_groq
GROQ_MODEL=llama-3.1-8b-instant
```

## Uso

### Notebook Jupyter

1. Inicia Jupyter:
```bash
jupyter notebook
```

2. Abre `main.ipynb`

3. Ejecuta las celdas en orden

### Uso Program√°tico

```python
from llm_providers import get_llm_client

# Obtener cliente LLM (usa la configuraci√≥n de .env)
llm = get_llm_client("groq")

# Usar el cliente
response = llm.invoke("¬øQu√© art√≠culo protege la libertad de expresi√≥n?")
print(response.content)
```

### Cambiar de Proveedor

```python
# OpenAI
llm = get_llm_client("openai", model="gpt-4")

# OpenRouter
llm = get_llm_client("openrouter", model="anthropic/claude-3-opus")

# Ollama (local)
llm = get_llm_client("ollama", model="llama3.2")

# Groq
llm = get_llm_client("groq", model="mixtral-8x7b-32768")
```

## Arquitectura

El proyecto utiliza una arquitectura modular:

- **`llm_providers.py`**: M√≥dulo con clases para diferentes proveedores LLM
  - `BaseLLMProvider`: Clase base abstracta
  - `OpenAIProvider`: Implementaci√≥n para OpenAI
  - `OpenRouterProvider`: Implementaci√≥n para OpenRouter
  - `OllamaProvider`: Implementaci√≥n para Ollama
  - `GroqProvider`: Implementaci√≥n para Groq
  - `LLMProviderFactory`: Factory para crear proveedores

- **`main.ipynb`**: Notebook principal con toda la funcionalidad
  - Loaders de documentos (PDF, TXT, MD)
  - Transformadores y splitters
  - Embeddings y Vector DB
  - Pipeline RAG
  - Agentes ReAct
  - Interfaz con widgets

## Documentos de Ejemplo

Los documentos legales de ejemplo est√°n en la carpeta `data/`:
- Constituci√≥n Pol√≠tica de Colombia (1991)
- Reglamento acad√©mico de pregrado

## Desarrollo

### Estructura del Proyecto

```
.
‚îú‚îÄ‚îÄ main.ipynb              # Notebook principal
‚îú‚îÄ‚îÄ llm_providers.py        # M√≥dulo de proveedores LLM
‚îú‚îÄ‚îÄ data/                   # Documentos legales
‚îú‚îÄ‚îÄ pyproject.toml          # Configuraci√≥n del proyecto
‚îú‚îÄ‚îÄ .env.example            # Plantilla de variables de entorno
‚îú‚îÄ‚îÄ ROADMAP.md             # Plan del proyecto
‚îî‚îÄ‚îÄ README.md              # Este archivo
```

### Agregar un Nuevo Proveedor

1. Crear una nueva clase heredando de `BaseLLMProvider`
2. Implementar los m√©todos abstractos
3. Registrar en `LLMProviderFactory.PROVIDERS`
4. Actualizar `.env.example` con las variables necesarias

## Limitaciones

- Los resultados deben ser verificados por profesionales legales
- La cobertura depende de los documentos indexados
- Requiere API key v√°lida o servidor Ollama local
- Los modelos pueden tener limitaciones de contexto

## Licencia

Este proyecto es para fines educativos.

## Contribuidores

Proyecto desarrollado para el curso de LangChain y LLMs.
